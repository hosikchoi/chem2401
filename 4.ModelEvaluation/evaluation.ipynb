{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **성능평가**\n",
    "학습이 완료되면 모델의 성능을 평가하여 모델이 좋은지 나쁜지 확인해야 한다. 모델의 성능을 평가하기 위한 기준은 몇 가지가 있다.\n",
    "\n",
    "### **정확도(Accuracy)**\n",
    "정확도(accuracy)는 가장 많이 사용되는 성능 평가 기준이다.\n",
    "\n",
    "`정확도 = (올바르게 분류한 샘플 수) / (전체 샘플 수)`\n",
    "\n",
    "정확도는 가장 많이 사용되지만 절대적인 것은 아니며, 한 클래스가 다른 클래스에 비해 항상 월등하게 많다면 문제가 된다.\n",
    "\n",
    "### **혼동 행렬(Confusion Matrix)** -> 2 * 2 도표 추가!!\n",
    "혼동 행렬(Confusion Matrix)은 모델이 예측을 하면서 얼마나 혼동하고 있는지를 나타내는 행렬이다.\n",
    "\n",
    "혼동 행렬을 알기 위해 필요한 네 가지 개념이 있다.\n",
    "- TP(True Positive) - 긍정을 긍정으로 올바르게 예측한 것\n",
    "- FN(False Negative) - 긍정을 부정으로 잘못 예측한 것\n",
    "- FP(False Positive) - 부정을 긍정으로 잘못 예측한 것\n",
    "- TN(True Negative) - 부정을 부정으로 올바르게 예측한 것\n",
    "\n",
    "혼동 행렬 표로부터 모델의 성능을 측정하는 4가지 지표가 있다.\n",
    "1. `정확도(Accuracy) = (TP + TN) / (TP + FN + FP + TN)`\n",
    "2. `재현도(Recall) = (TP) / (TP + FN)`\n",
    "3. `정밀도(Precision) = (TP) / (TP + FP)`\n",
    "4. `F1 score = 2 / {(1 / Recall) + (1 / Precision)} = 2 * (Recall * Precision) / (Recall + Precision)`\n",
    "\n",
    "예를 들어, 관심 범주가 질병이 있는 환자라면, 정확도는 전체 중에서 환자를 환자로, 정상인을 정상인으로 진단한 비율이다. \n",
    "\n",
    "재현도는 실제 질병이 있는 사람을 환자라고 진단한 비율이다. 정밀도는 질병이 있다고 진단한 사람 중 실제 환자의 비율이다. \n",
    "\n",
    "F1 score는 재현도와 정밀도의 성능을 동시에 고려하기 위해 사용하는 지표이다. 재현도와 정밀도의 조화 평균이며, 0과 1 사이의 값을 가지며 1에 가까울수록 성능이 좋음을 나타낸다.\n",
    "\n",
    "우리가 사용할 지표는 F1 score인데, 이 지표는 클래스 간 데이터의 불균형이 심할 때 유용하다. 우리가 사용할 데이터는 클래스 간 불균형이 심하기 때문에 이 지표를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 예시를 통해 Recall과 Precision을 이용해서 F1_score를 계산해보고, 이를 f1_score 함수로 계산한 값과 비교해보자.\n",
    "\n",
    "Recall, Precision, F1_score를 계산하는 함수를 사용하기 위해 sckit-learn 모듈의 metrics 클래스에서 recall_score, precision_score, f1_score 함수를 import한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "\trecall_score,\n",
    "\tprecision_score,\n",
    "\tf1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score: 1.0\n",
      "precision score: 0.6666666666666666\n",
      "my_f1_score: 0.8\n",
      "f1_score: 0.8\n"
     ]
    }
   ],
   "source": [
    "y_true = [0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
    "y_predict = [0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
    "\n",
    "rec_score = recall_score(y_true, y_predict)\n",
    "print(\"recall score:\", rec_score)\n",
    "prec_score = precision_score(y_true, y_predict)\n",
    "print(\"precision score:\", prec_score)\n",
    "\n",
    "my_f1_score = 2 * (rec_score * prec_score) / (rec_score + prec_score)\n",
    "print(\"my_f1_score:\", my_f1_score)\n",
    "print(\"f1_score:\",f1_score(y_true, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train/Test 관련**\n",
    "모델의 성능을 평가하기 위해 데이터를 두 부분으로 나눠야 한다. \n",
    "\n",
    "데이터의 일부는 모델의 학습에 사용되고 이를 훈련(train) 데이터라고 한다. 데이터의 나머지 부분은 훈련된 모델의 성능을 평가하는 데 사용되고 이를 테스트(test) 데이터라고 한다.\n",
    "\n",
    "이렇게 데이터를 두 부분으로 나눠서 훈련에 사용되지 않은 데이터로 평가를 하는 이유는 모델이 과적합이 되지 않고 일반화 되었는지 평가하기 위함이다. \n",
    "\n",
    "과적합(overfitting)이란 훈련 데이터에 너무 많이 학습되어 훈련 데이터에 대해서는 높은 성능을 보이지만, 새로운 데이터에 대해서는 성능이 저하되는 현상을 의미한다. \n",
    "\n",
    "즉, 훈련 데이터에 대해서 과하게 학습되지 않고 일반화된 성능을 평가하기 위해 데이터를 두 부분으로 나누어 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cross Validation**\n",
    "교차 검증(Cross Validation)이란 모델을 학습시킬 때 훈련 데이터를 또 다시 훈련 데이터와 검증(validation) 데이터로 나누어 훈련 데이터로 학습한 후, 검증 데이터를 통해 모델의 성능을 평가하는 방법이다.\n",
    "\n",
    "교차 검증의 장점은 특정 데이터에 대한 과적합을 방지하고, 일반화된 모델을 만들 수 있게 해주는 것 등이 있다.\n",
    "\n",
    "교차 검증의 단점은 모델에 대한 훈련 및 평가에 소요되는 시간이 증가한다는 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **K-fold Cross Validation(K-fold 사진 추가)**\n",
    "K-fold Cross Validation은 모델의 성능을 평가하는 기법 중 하나로, 데이터를 K개의 fold로 나누고 K번의 실험을 통해 모델의 성능을 평가한다.\n",
    "\n",
    "각 실험에서 하나의 fold를 테스트 데이터로 사용하고, 나머지 K-1개의 fold를 훈련 데이터로 사용한다.\n",
    "\n",
    "테스트 데이터로 사용할 fold를 바꿔가며 총 K번 실험을 진행하여 얻은 성능 지표의 평균을 최종 성능 지표로 사용한다.\n",
    "\n",
    "K-fold Cross Validation을 사용하면 데이터가 적더라도 신뢰성을 확보할 수 있다.\n",
    "\n",
    "다음은 K-fold Cross Validation을 하는 예시이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold CV의 실습을 하기 전에 여기서 사용할 데이터에 대해 알아보자.\n",
    "\n",
    "이번 예시에서 사용할 데이터는 tox21 데이터이다.\n",
    "\n",
    "tox21 데이터는 총 166개의 속성(maccs_1, ..., maccs166)과 1개의 라벨(NR-AR)으로 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표 형식의 데이터 등 다양한 데이터를 쉽게 다룰 수 있도록(데이터 결합 등) 해주는 모듈\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11130, 167)\n"
     ]
    }
   ],
   "source": [
    "# 사용할 데이터가 들어있는 폴더\n",
    "folder = '../chem2401/0.Data'\n",
    "# 사용할 데이터의 파일명\n",
    "train_data_file = 'tox21_train.csv'\n",
    "# /chem2401/Data/tox21_dataset.csv과 같이 파일 경로로 만듦\n",
    "train_file_path = f'{folder}/{train_data_file}'\n",
    "\n",
    "# 파일 경로에 해당하는 csv 파일 불러오기\n",
    "# csv 파일이란 comma-separated values로, 쉼표로 구분된 데이터 파일임\n",
    "df = pd.read_csv(train_file_path)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data에서 feature 부분과 label 부분 분리\n",
    "feature = df.iloc[:, :166]\n",
    "label = df.iloc[:, 166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "# 범주형 변수 예측에 사용되는 모델 중 하나\n",
    "# 분류 문제(0인지 1인지 분류처럼)에 사용되는 기계학습 알고리즘 중 하나\n",
    "# 현재 예시에서 사용할 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# scikit-learn에서 제공하는 K-Fold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My K-fold Accuracies: [0.82659479 0.82749326 0.89218329 0.84141959 0.83468104]\n",
      "My K-fold Mean Accuracy: 0.8444743935309973\n"
     ]
    }
   ],
   "source": [
    "# ================My K-fold================\n",
    "\n",
    "# k-fold에서 데이터를 몇 개의 fold로 나눌 지 정함\n",
    "k = 5\n",
    "\n",
    "# feature의 데이터 개수를 저장\n",
    "size = len(feature)\n",
    "\n",
    "# feature를 k개의 fold로 나누기 위해 몇 개의 데이터 단위로 끊어야 하는 지 계산\n",
    "fold_size = (int)(size / k)\n",
    "\n",
    "# 각 실험에 대한 accuracy를 저장하기 위한 배열\n",
    "accuracies = np.empty(k)\n",
    "\n",
    "# fold 개수만큼 실험 반복\n",
    "for i in range(k):\n",
    "\t# [arange 함수 참고]\n",
    "\t# numpy 모듈의 arange 함수는 인자로 들어온 범위만큼의 등차수열 배열을 반환\n",
    "\t# 사용 -> np.arange(start, end, step) (start와 step을 지정해주지 않으면 각각 0, 1이 기본값으로 적용)\n",
    "\t# ex. np.arange(0, 10, 1) -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\t# ex. np.arange(10) -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "\t# [concatenate 함수 참고]\n",
    "\t# numpy 모듈의 concatenate 함수는 인자로 들어온 배열을 합쳐서 새로운 배열을 반환\n",
    "\t# ex. np.concatenate((np.array([1, 2, 3]), np.array([4, 5, 6]))) -> [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "\t# 분할할 test data & train data의 index 저장\n",
    "\t\t# feature 중에서 test data로 사용할 부분의 index 저장\n",
    "\t\t# 즉, test data로 사용할 fold의 index를 저장\n",
    "\ttest_indexs = np.arange(i * fold_size, (i + 1) * fold_size)\n",
    "\t\t# test data로 사용할 부분을 제외한 부분의 index를 합쳐서 저장\n",
    "\t\t# train data로 사용할 부분의 index임\n",
    "\ttrain_indexs = np.concatenate((np.arange(i * fold_size), np.arange((i + 1) * fold_size, size)))\n",
    "\n",
    "\t# test data & train data 생성\n",
    "\t# X 중에서 위에서 지정한 index에 해당하는 값을 train과 test에 나누어 저장\n",
    "\tfeature_test = feature.iloc[test_indexs]\n",
    "\tlabel_test = label.iloc[test_indexs]\n",
    "\tfeature_train = feature.iloc[train_indexs]\n",
    "\tlabel_train = label.iloc[train_indexs]\n",
    "\n",
    "\t# 사용할 모델 지정(Logistic Regression 모델 사용)\n",
    "\tmodel = LogisticRegression()\n",
    "\n",
    "\t# 모델에 학습\n",
    "\tmodel.fit(feature_train, label_train)\n",
    "\n",
    "\t# 매 실험마다 계산한 정확도를 accuracies 배열에 하나씩 저장\n",
    "\t# feature_test의 test data에 대해 위에서 학습한 모델이 추측한 결과와 실제 정답인 label_test를 비교하여 accuracy 계산\n",
    "\taccuracies[i] = model.score(feature_test, label_test)\n",
    "\n",
    "# 위에서 계산한 전체 accuracy 출력\n",
    "print(\"My K-fold Accuracies:\", accuracies)\n",
    "\n",
    "# 모든 accuracy의 평균을 계산하여 최종 accuracy 출력\n",
    "print(\"My K-fold Mean Accuracy:\", accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================Scikit K-fold================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2226  2227  2228 ... 11127 11128 11129] [   0    1    2 ... 2223 2224 2225]\n",
      "[    0     1     2 ... 11127 11128 11129] [2226 2227 2228 ... 4449 4450 4451]\n",
      "[    0     1     2 ... 11127 11128 11129] [4452 4453 4454 ... 6675 6676 6677]\n",
      "[    0     1     2 ... 11127 11128 11129] [6678 6679 6680 ... 8901 8902 8903]\n",
      "[   0    1    2 ... 8901 8902 8903] [ 8904  8905  8906 ... 11127 11128 11129]\n",
      "Scikit-learn K-fold Accuracies: [0.82659479 0.82749326 0.89218329 0.84141959 0.83468104]\n",
      "Scikit-learn K-fold Mean Accuracy: 0.8444743935309973\n"
     ]
    }
   ],
   "source": [
    "# [방법 1]\n",
    "\n",
    "# k-fold에서 데이터를 몇 개의 fold로 나눌 지 정함\n",
    "k = 5\n",
    "\n",
    "# k개의 fold로 cross validation하는 K-Fold 객체 생성\n",
    "kfold = KFold(n_splits = k)\n",
    "\n",
    "# 사용할 모델 지정(Logistic Regression 모델 사용)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 각 실험에 대한 accuracy를 저장하기 위한 배열\n",
    "accuracies = np.empty(k)\n",
    "\n",
    "# k번 만큼 실험을 반복하며, 매 회차마다의 train 데이터를 다시 train과 validation data 범위의 index를 각각 train_index와 test_index에 저장\n",
    "for train_index, test_index in kfold.split(feature, label):\n",
    "\t# index 범위 출력해서 확인\n",
    "\tprint(train_index, test_index)\n",
    "\t\n",
    "\t# train data & test data 생성\n",
    "\t# feature 중에서 위에서 지정한 index에 해당하는 값을 train과 test 나누어 저장\n",
    "\tfeature_train, feature_test = feature.iloc[train_index], feature.iloc[test_index]\n",
    "\tlabel_train, label_test = label.iloc[train_index], label.iloc[test_index]\n",
    "\n",
    "\t# 모델에 학습\n",
    "\tmodel.fit(feature_train, label_train)\n",
    "\n",
    "\t# 매 실험마다 계산한 정확도를 accuracies 배열에 하나씩 저장\n",
    "\t# X_test의 test data에 대해 위에서 학습한 모델이 추측한 결과와 실제 정답인 y_test를 비교하여 accuracy 계산\n",
    "\taccuracies[i] = model.score(feature_test, label_test)\n",
    "\n",
    "\n",
    "# 위에서 계산한 전체 accuracy 출력\n",
    "print(\"Scikit-learn K-fold Accuracies:\", accuracies)\n",
    "\n",
    "# 모든 accuracy의 평균을 계산하여 최종 accuracy 출력\n",
    "print(\"Scikit-learn K-fold Mean Accuracy:\", accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn K-fold Accuracies: [0.82659479 0.82749326 0.89218329 0.84141959 0.83468104]\n",
      "Scikit-Learn K-fold Mean Accuracy: 0.8444743935309973\n"
     ]
    }
   ],
   "source": [
    "# [방법 2]\n",
    "\n",
    "# cross validation에서 score를 계산하는 함수\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# k-fold에서 데이터를 몇 개의 fold로 나눌 지 정함\n",
    "k = 5\n",
    "\n",
    "# k개의 fold로 cross validation하는 K-Fold 객체 생성\n",
    "kfold = KFold(n_splits = k)\n",
    "\n",
    "# 사용할 모델 지정(Logistic Regression 모델 사용)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 사용할 model, X, y, 사용할 cross validation 객체로 cross validation 했을 때의 accuracy 배열을 results에 저장\n",
    "results = cross_val_score(model, feature, label, cv = kfold)\n",
    "\n",
    "# 전체 accuracy 출력\n",
    "print(\"Scikit-Learn K-fold Accuracies:\", results)\n",
    "\n",
    "# 모든 accuracy의 평균을 계산하여 최종 accuracy 출력\n",
    "print(\"Scikit-Learn K-fold Mean Accuracy:\", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 K-fold CV를 직접 구현한 결과와 Scikit-Learn의 K-fold를 사용한 결과 모두 동일함을 알 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 데이터가 불균형한 경우 K-fold는 효과적이지 않을 수 있다.\n",
    "\n",
    "예를 들어, true가 100000개 있고 false가 50개라고 했을 때, K-fold를 적용하게 된다면 false가 없는 부분만 학습을 하고 false를 분류할 수 없는 상황이 발생할 수 있다.\n",
    "\n",
    "이와 같이, 데이터가 불균형한 경우에 사용할 수 있는 방법이 Stratified K-fold Cross Validation이다.\n",
    "\n",
    "이러한 K-fold Cross Validation의 문제를 해결하기 위해 Stratified K-fold Cross Validation을 배워보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Stratified K-fold Cross Validation**\n",
    "\n",
    "Stratified K-fold Cross Validation이란 K-fold CV의 target의 비율을 균일하게 유지 못한다는 문제점을 해결하여 target의 비율을 균일하게 해주는 방식이다.\n",
    "\n",
    "우리가 추후 사용할 데이터는 불균형 데이터이기 때문에 Stratified K-fold Cross Validation을 사용할 예정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-fold Accuracies: [0.88140162 0.88005391 0.89892183 0.89308176 0.88993711]\n",
      "Stratified K-fold Mean Accuracy: 0.8886792452830189\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# k-fold에서 데이터를 몇 개의 fold로 나눌 지 정함\n",
    "k = 5\n",
    "\n",
    "# k개의 fold로 cross validation하는 Stratified K-Fold 객체 생성\n",
    "strkfold = StratifiedKFold(n_splits = k)\n",
    "\n",
    "# 사용할 모델 지정(Logistic Regression 모델 사용)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 각 실험에 대한 accuracy를 저장하기 위한 배열\n",
    "accuracies = np.empty(k)\n",
    "\n",
    "# 반복문이 돌아가면서 accuracies 배열에 값을 저장하기 위한 index 변수\n",
    "i = 0\n",
    "\n",
    "# k번 만큼 실험을 반복하며, 매 회차마다의 train과 test data 범위의 index를 각각 train_index와 test_index에 저장\n",
    "for train_index, test_index in strkfold.split(feature, label):\n",
    "\t# test data & train data 생성\n",
    "\t# X 중에서 위에서 지정한 index에 해당하는 값을 train과 test에 나누어 저장\n",
    "\tfeature_train, feature_test = feature.iloc[train_index], feature.iloc[test_index]\n",
    "\tlabel_train, label_test = label.iloc[train_index], label.iloc[test_index]\n",
    "\n",
    "\t# 모델에 학습\n",
    "\tmodel.fit(feature_train, label_train)\n",
    "\n",
    "\t# 매 실험마다 계산한 정확도를 accuracies 배열에 하나씩 저장\n",
    "\t# X_test의 test data에 대해 위에서 학습한 모델이 추측한 결과와 실제 정답인 y_test를 비교하여 accuracy 계산\n",
    "\taccuracies[i] = model.score(feature_test, label_test)\n",
    "\t\n",
    "\ti = i + 1\n",
    "\n",
    "\n",
    "# 위에서 계산한 전체 accuracy 출력\n",
    "print(\"Stratified K-fold Accuracies:\", accuracies)\n",
    "\n",
    "# 모든 accuracy의 평균을 계산하여 최종 accuracy 출력\n",
    "print(\"Stratified K-fold Mean Accuracy:\", accuracies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation 시작**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 표 형식의 데이터 등 다양한 데이터를 쉽게 다룰 수 있도록(데이터 결합 등) 해주는 모듈\n",
    "import pandas as pd\n",
    "\n",
    "# Stratified K-Fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11130, 167)\n",
      "(1453, 167)\n"
     ]
    }
   ],
   "source": [
    "# 사용할 데이터가 들어있는 폴더\n",
    "folder = '../chem2401/0.Data'\n",
    "# 사용할 데이터의 파일명\n",
    "train_data_file = 'tox21_train.csv'\n",
    "test_data_file = 'tox21_test.csv'\n",
    "# /chem2401/Data/tox21_dataset.csv과 같이 파일 경로로 만듦\n",
    "train_file_path = f'{folder}/{train_data_file}'\n",
    "test_file_path = f'{folder}/{test_data_file}'\n",
    "\n",
    "# 파일 경로에 해당하는 csv 파일 불러오기\n",
    "# csv 파일이란 comma-separated values로, 쉼표로 구분된 데이터 파일임\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data와 test_data에서 feature 부분과 label 부분 분리\n",
    "feature_train = train_data.iloc[:, :166]\n",
    "feature_test = test_data.iloc[:, :166]\n",
    "label_train = train_data.iloc[:, 166]\n",
    "label_test = test_data.iloc[:, 166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 시행 시 같은 난수를 추출하기 위해 seed값 지정\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Logistic Regression 모델 사용**\n",
    "### **Logistic Regression 튜닝**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic 모델의 hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_params_dictionary = {\n",
    "\t# \n",
    "\t'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 7, 9, 11, 15, 20, 25, 30, 35, 40, 50, 100],\n",
    "\t#\n",
    "\t'penalty': ['l1', 'l2'],\n",
    "\t#\n",
    "\t'solver': ['liblinear', 'saga']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression 모델에서 위 hyperparameter로 만들 수 있는 가능한 모든 조합 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_param_dict가 dictionary인지 확인\n",
    "if not isinstance(logistic_params_dictionary, dict):\n",
    "\traise TypeError('Parameter grid is not a dict ({!r})'.format(logistic_params_dictionary))\n",
    "\n",
    "if isinstance(logistic_params_dictionary, dict):\n",
    "\t# logistic_param_dict가 반복 가능(iterable)한지 확인\n",
    "\tfor key in logistic_params_dictionary:\n",
    "\t\tif not isinstance(logistic_params_dictionary[key], Iterable):\n",
    "\t\t\traise TypeError('Parameter grid value is not iterable '\n",
    "\t\t\t\t\t\t\t'(key={!r}, value={!r})'.format(key, logistic_params_dictionary[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary를 key의 알파벳 순으로 정렬\n",
    "items = sorted(logistic_params_dictionary.items())\n",
    "\n",
    "# 다음과 같이 key는 key끼리, value는 value끼리 모아서 저장\n",
    "# ('C', 'penalty', 'solver')\n",
    "# ([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 7, 9, 11, 15, 20, 25, 30, 35, 40, 50, 100], ['l1', 'l2'], ['liblinear', 'saga'])\n",
    "keys, values = zip(*items)\n",
    "\n",
    "logistic_params_grid = []\n",
    "\n",
    "# product(*value)에서 value들의 가능한 모든 조합 생성\n",
    "# (0.1, 'l1', 'liblinear')처럼...\n",
    "for v in product(*values):\n",
    "\t# {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'} 이런 식으로 만들어서 하나씩 추가\n",
    "\tlogistic_params_grid.append(dict(zip(keys, v))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.2, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.2, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.2, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.2, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.3, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.3, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.3, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.3, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.4, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.4, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.4, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.4, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.5, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.5, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.5, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.5, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.6, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.6, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.6, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.6, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.7, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.7, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.7, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.7, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.8, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.8, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.8, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.8, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.9, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 0.9, 'penalty': 'l1', 'solver': 'saga'}, {'C': 0.9, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 0.9, 'penalty': 'l2', 'solver': 'saga'}, {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 1, 'penalty': 'l1', 'solver': 'saga'}, {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 1, 'penalty': 'l2', 'solver': 'saga'}, {'C': 2, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 2, 'penalty': 'l1', 'solver': 'saga'}, {'C': 2, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 2, 'penalty': 'l2', 'solver': 'saga'}, {'C': 3, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 3, 'penalty': 'l1', 'solver': 'saga'}, {'C': 3, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 3, 'penalty': 'l2', 'solver': 'saga'}, {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 4, 'penalty': 'l1', 'solver': 'saga'}, {'C': 4, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 4, 'penalty': 'l2', 'solver': 'saga'}, {'C': 5, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 5, 'penalty': 'l1', 'solver': 'saga'}, {'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 5, 'penalty': 'l2', 'solver': 'saga'}, {'C': 7, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 7, 'penalty': 'l1', 'solver': 'saga'}, {'C': 7, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 7, 'penalty': 'l2', 'solver': 'saga'}, {'C': 9, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 9, 'penalty': 'l1', 'solver': 'saga'}, {'C': 9, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 9, 'penalty': 'l2', 'solver': 'saga'}, {'C': 11, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 11, 'penalty': 'l1', 'solver': 'saga'}, {'C': 11, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 11, 'penalty': 'l2', 'solver': 'saga'}, {'C': 15, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 15, 'penalty': 'l1', 'solver': 'saga'}, {'C': 15, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 15, 'penalty': 'l2', 'solver': 'saga'}, {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 20, 'penalty': 'l1', 'solver': 'saga'}, {'C': 20, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 20, 'penalty': 'l2', 'solver': 'saga'}, {'C': 25, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 25, 'penalty': 'l1', 'solver': 'saga'}, {'C': 25, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 25, 'penalty': 'l2', 'solver': 'saga'}, {'C': 30, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 30, 'penalty': 'l1', 'solver': 'saga'}, {'C': 30, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 30, 'penalty': 'l2', 'solver': 'saga'}, {'C': 35, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 35, 'penalty': 'l1', 'solver': 'saga'}, {'C': 35, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 35, 'penalty': 'l2', 'solver': 'saga'}, {'C': 40, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 40, 'penalty': 'l1', 'solver': 'saga'}, {'C': 40, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 40, 'penalty': 'l2', 'solver': 'saga'}, {'C': 50, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 50, 'penalty': 'l1', 'solver': 'saga'}, {'C': 50, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 50, 'penalty': 'l2', 'solver': 'saga'}, {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 100, 'penalty': 'l1', 'solver': 'saga'}, {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 100, 'penalty': 'l2', 'solver': 'saga'}]\n"
     ]
    }
   ],
   "source": [
    "# parameter 조합 출력\n",
    "print(logistic_params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# 가능한 parameter 조합 개수 출력\n",
    "print(len(logistic_params_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic 평가 시작**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 딕셔너리 만들기\n",
    "result = {}\n",
    "result['model'] = {}\n",
    "result['f1'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inhalation-main/module/common.py\n",
    "\n",
    "binary_cross_validation 함수 참고했음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic의 parameter의 모든 경우의 수에 대해 f1_score 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:54<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(range(len(logistic_params_grid))):\n",
    "\tresult['model']['model'+str(p)] = logistic_params_grid[p]\n",
    "\tresult['f1']['model'+str(p)] = []\n",
    "\t\n",
    "\t# logistic_params_grid[p] 딕셔너리를 인자로 넘겨줄 때 ** 사용\n",
    "\t# ex. LogisticRegression(random_state=seed, C=1.0, penalty='l2', solver='lbfgs')\n",
    "\tmodel = LogisticRegression(random_state = seed, **logistic_params_grid[p])\n",
    "\tskf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)\n",
    "    \n",
    "\tmetrics = ['f1']\n",
    "\n",
    "\ttrain_metrics = list(map(lambda x: 'train_' + x, metrics))\n",
    "\tval_metrics = list(map(lambda x: 'val_' + x, metrics))\n",
    "\n",
    "\ttrain_f1 = []\n",
    "\tval_f1 = []\n",
    "\n",
    "\tfor train_idx, val_idx in skf.split(feature_train, label_train):\n",
    "\t\tsplited_train_x, splited_train_y = feature_train.iloc[train_idx], label_train.iloc[train_idx]\n",
    "\t\tsplited_val_x, splited_val_y = feature_train.iloc[val_idx], label_train.iloc[val_idx]\n",
    "\n",
    "\t\tmodel.fit(splited_train_x, splited_train_y)\n",
    "\t\ttrain_pred = model.predict(splited_train_x)\n",
    "\t\tval_pred = model.predict(splited_val_x)\n",
    "\t\t\n",
    "\t\ttrain_f1.append(f1_score(splited_train_y, train_pred))\n",
    "\t\tval_f1.append(f1_score(splited_val_y, val_pred))\n",
    "\n",
    "\tcv_result = dict(zip(train_metrics + val_metrics, [np.mean(train_f1), np.mean(val_f1)]))\n",
    "\n",
    "\tresult['f1']['model'+str(p)].append(cv_result['val_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameter 찾기\n",
    "mean_list = list(map(lambda x: np.mean(x[1]), result['f1'].items()))\n",
    "max_idx = mean_list.index(max(mean_list))\n",
    " \n",
    "best_param = result['model'][f'model{max_idx}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_param이 위치한 index 찾기\n",
    "m = list(result['model'].keys())[list(result['model'].values()).index(best_param)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'C': 15, 'penalty': 'l1', 'solver': 'liblinear'} \t\t\n",
      "=====validation result===== \t\t\n",
      "f1: 0.896(0.000)\n"
     ]
    }
   ],
   "source": [
    "# val result 출력\n",
    "f1 = result['f1'][m]\n",
    "\n",
    "print(f\"best param: {best_param} \\\n",
    "\t\t\\n=====validation result===== \\\n",
    "\t\t\\nf1: {np.mean(f1):.3f}({np.std(f1):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====test result===== \t\t\n",
      "best param: {'C': 15, 'penalty': 'l1', 'solver': 'liblinear'} \t\t\n",
      "f1: 0.252\n"
     ]
    }
   ],
   "source": [
    "# test result 출력\n",
    "\n",
    "# 최종으로 나온 best parameter 넣고 test 해야될듯! 수정 필요!\n",
    "model = LogisticRegression(random_state = seed, **logistic_params_grid[p])\n",
    "\n",
    "model.fit(feature_train, label_train)\n",
    "\n",
    "pred = model.predict(feature_test)\n",
    "pred_score = model.predict_proba(feature_test)[:, 1]\n",
    "\t\n",
    "print(f'=====test result===== \\\n",
    "\t\t\\nbest param: {best_param} \\\n",
    "\t\t\\nf1: {f1_score(label_test, pred):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. MLP 모델 사용**\n",
    "### **MLP hyperparameter 튜닝**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP의 hyperparameter\n",
    "params_dict = {\n",
    "\t# \n",
    "\t'hidden_layer_sizes': [(50), (100, 50, 10)],\n",
    "\t# \n",
    "\t'activation': ['relu', 'tanh'],\n",
    "\t# \n",
    "\t'solver': ['adam', 'sgd'],\n",
    "\t# \n",
    "\t'alpha': [0.0001, 0.001],\n",
    "\t# \n",
    "\t'learning_rate_init': [0.001, 0.01],\n",
    "\t# \n",
    "\t'max_iter': [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MLP 모델에서 위 hyperparameter로 만들 수 있는 가능한 모든 조합 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_dict가 dictionary인지 확인\n",
    "if not isinstance(params_dict, dict):\n",
    "\traise TypeError('Parameter grid is not a dict ({!r})'.format(params_dict))\n",
    "\n",
    "# params_dict가 dictionary라면\n",
    "if isinstance(params_dict, dict):\n",
    "\t# param_dict가 반복 가능(iterable)한지 확인\n",
    "\tfor key in params_dict:\n",
    "\t\tif not isinstance(params_dict[key], Iterable):\n",
    "\t\t\traise TypeError('Parameter grid value is not iterable '\n",
    "\t\t\t\t\t\t\t'(key={!r}, value={!r})'.format(key, params_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary를 key의 알파벳 순으로 정렬\n",
    "items = sorted(params_dict.items())\n",
    "\n",
    "# 다음과 같이 key는 key끼리, value는 value끼리 모아서 저장\n",
    "# ('activation', 'alpha', 'hidden_layer_sizes', 'learning_rate_init', 'max_iter', 'solver')\n",
    "# (['relu', 'tanh'], [0.0001, 0.001], [50, (100, 50, 10)], [0.001, 0.01], [50, 100], ['adam', 'sgd'])\n",
    "keys, values = zip(*items)\n",
    "\n",
    "# 조합된 parameter를 담을 list 선언\n",
    "params_grid = []\n",
    "\n",
    "# product(*value)에서 value들의 가능한 모든 조합 생성\n",
    "# ('relu', 0.0001, 50, 0.001, 50, 'adam')처럼...\n",
    "for v in product(*values):\n",
    "\t# {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}\n",
    "\t# 이런 식으로 만들어서 하나씩 추가\n",
    "\tparams_grid.append(dict(zip(keys, v))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 50, 'solver': 'sgd'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}, {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100, 50, 10), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd'}]\n"
     ]
    }
   ],
   "source": [
    "# parameter 조합 출력\n",
    "print(params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# 가능한 parameter 조합 개수 출력\n",
    "print(len(params_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 딕셔너리 만들기\n",
    "result = {}\n",
    "result['model'] = {}\n",
    "result['f1'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [21:16<00:00, 19.94s/it]\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(range(len(params_grid))):\n",
    "\tresult['model']['model'+str(p)] = params_grid[p]\n",
    "\tresult['f1']['model'+str(p)] = []\n",
    "\n",
    "\t# params_grid[p] 딕셔너리를 인자로 넘겨줄 때 ** 사용\n",
    "\t# ex. LogisticRegression(random_state=seed, C=1.0, penalty='l2', solver='lbfgs')\n",
    "\t# load_model() 부분\n",
    "\tmodel = MLPClassifier(random_state = seed, **params_grid[p])\n",
    "\tskf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)\n",
    "    \n",
    "\tmetrics = ['f1']\n",
    "\n",
    "\ttrain_metrics = list(map(lambda x: 'train_' + x, metrics))\n",
    "\tval_metrics = list(map(lambda x: 'val_' + x, metrics))\n",
    "\n",
    "\ttrain_f1 = []\n",
    "\tval_f1 = []\n",
    "\n",
    "\tfor train_idx, val_idx in skf.split(feature_train, label_train):\n",
    "\t\ttrain_x, train_y = feature_train.iloc[train_idx], label_train.iloc[train_idx]\n",
    "\t\tval_x, val_y = feature_train.iloc[val_idx], label_train.iloc[val_idx]\n",
    "\n",
    "\t\tmodel.fit(train_x, train_y)\n",
    "\t\ttrain_pred = model.predict(train_x)\n",
    "\t\ttrain_pred_score = model.predict_proba(train_x)[:, 1]\n",
    "\t\tval_pred = model.predict(val_x)\n",
    "\t\tval_pred_score = model.predict_proba(val_x)[:, 1]\n",
    "\t\t\n",
    "\t\ttrain_f1.append(f1_score(train_y, train_pred))\n",
    "\t\tval_f1.append(f1_score(val_y, val_pred))\n",
    "\n",
    "\tcv_result = dict(zip(train_metrics + val_metrics, [np.mean(train_f1), np.mean(val_f1)]))\n",
    "\n",
    "\tresult['f1']['model'+str(p)].append(cv_result['val_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameter 찾기\n",
    "mean_list = list(map(lambda x: np.mean(x[1]), result['f1'].items()))\n",
    "max_idx = mean_list.index(max(mean_list))\n",
    " \n",
    "best_param = result['model'][f'model{max_idx}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_param이 위치한 index 찾기\n",
    "m = list(result['model'].keys())[list(result['model'].values()).index(best_param)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val result 출력\n",
    "f1 = result['f1'][m]\n",
    "\n",
    "print(f\"best param: {best_param} \\\n",
    "\t\t\\n=====validation result===== \\\n",
    "\t\t\\nf1: {np.mean(f1):.3f}({np.std(f1):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 모델이 아니라 best parameter를 넣어야함! 수정 필요!\n",
    "model = MLPClassifier(random_state = seed, **params_grid[p])\n",
    "\n",
    "model.fit(feature_train, label_train)\n",
    "\n",
    "pred = model.predict(label_test)\n",
    "pred_score = model.predict_proba(label_test)[:, 1]\n",
    "\t\n",
    "print(f'=====test result===== \\\n",
    "\t\t\\nbest param: {best_param} \\\n",
    "\t\t\\nf1: {f1_score(label_test, pred):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
