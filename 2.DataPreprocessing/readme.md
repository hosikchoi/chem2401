# 머신러닝 워크플로우 (Machine Learning Workflow)

## Workflow  
> 1) 데이터 수집 2) 탐색적 데이터 분석(EDA) 3) 데이터 전처리 4) 모델링 및 훈련 5) 모델 성능 평가 6) 배포
> 
![image](https://github.com/user-attachments/assets/d260ba30-1453-42b5-9ae4-b569e637ddfb)  
출처: https://wikidocs.net/31947

본 교재에서는 수집된 데이터를 이용하기 때문에, `1)데이터 수집`, `6) 배포`를 제외한 `2)EDA`, `3)데이터 전처리`, `4)모델링`, `5)모델 성능 평가`를 위주로 설명하겠습니다.    



## 1) 데이터 수집  

머신 러닝을 하기 위해서는 기계에 학습시켜야 할 데이터가 필요합니다. 목표에 맞는 데이터를 구해야 하며, 이를 위한 여러 데이터 수집 방법이 있습니다. 첫 번째로는 기업이나 연구 기관에서 제공하는 데이터베이스에서 데이터를 가져오는 방법이 있습니다. 예를 들면, 공공데이터 포털, Kaggle, UCI Machine Learning Repository 등이 있습니다. 두 번째로는 웹사이트에서 필요한 정보를 크롤링을 통해 직접 추출하는 방법입니다. 이 방식을 사용할 때에는 법적 이슈와 사이트의 규정을 준수해야 합니다. 이 외에도 설문조사 및 실험데이터, 센서 데이터, 데이터 증강 등 여러 데이터 수집 과정이 존재합니다.   

본 교재에서는 미국 환경보호청(EPA)에서 제공하는 데이터인 Tox21 데이터를 이용하였습니다.


   
## 2) 탐색적 데이터 분석 (Exploratory Data Analysis, EDA)  

데이터가 수집되었다면, 데이터를 점검하고 탐색하는 단계입니다. 데이터의 구조, 노이즈 데이터, 머신 러닝 적용을 위해서 데이터를 어떻게 정재해야하는지 등을 파악해야 합니다. 이 단계를 **탐색적 데이터 분석(Exploratory Data Analysis, EDA)** 라고 합니다. 이는 독립 변수, 종속 변수, 변수의 데이터 타입, 변수의 분포, 요약통계량 등을 점검하며 데이터의 특징과 내재하는 구조적 관계를 알아내는 과정으로 이 과정에서 시각화(ex. 히스토그램, box plot, 산점도)와 간단한 통계 검정(ex. 정규성 검정, 평균차이 검정, 상관관계 검정)을 진행하기도 합니다. EDA는 최종적으로는 모델의 정확성을 높이기 위한 전 단계 작업입니다. 그렇기 때문에 EDA 과정은 데이터 구조를 파악해 그에 맞는 처리 방법을 결정하는데 중요한 역할을 합니다.   

본 교재에서는 EDA 과정에서 시각화를 메인으로 합니다.

![image](https://github.com/user-attachments/assets/b004e8de-366b-419f-bf86-86087c9b255d)   
출처: seaborn 시각화 예제(https://kite-mo.github.io/python/2020/04/20/python-5-weeks/)

![image](https://github.com/user-attachments/assets/7f8a274e-bde7-4887-a472-ab3c9c87e908)   
출처: 평균 차이 검정 중 분산 분석(ANOVA) (https://recipesds.tistory.com/entry/%EB%B6%84%EC%82%B0%EB%B6%84%EC%84%9DANOVA-%EC%95%84%EB%8B%88-%EB%8B%A4%EC%A7%91%EB%8B%A8-%EC%B0%A8%EC%9D%B4%EC%97%90-%EC%99%9C-%EA%B0%91%EC%9E%90%EA%B8%B0-%EB%B6%84%EC%82%B0%EC%9D%84-%EB%B3%B4%EC%A7%80%EC%9A%94)

![image](https://github.com/user-attachments/assets/e831c2a6-d3a8-4f47-a04e-f90260780f18)   
출처: 피어슨 상관계수 (https://statisticsplaybook.com/covariance-and-correlation/)   


     
## 3) 데이터 전처리

데이터 전처리는 머신러닝 모델의 성능을 높이고 데이터의 품질을 향상시키기 위한 중요한 과정입니다. 데이터 전처리 과정에서는 필요에 따라서 수행하는 내용이 달라질 수 있습니다. 주로 결측치 처리, 데이터 스케일링, 인코딩, 이상치 처리, 특성 엔지니어링, 데이터 분리, 데이터 증강 등과 같은 다양한 방법을 수행합니다.   

1. 결측치 처리
> 결측치를 무시하면 데이터 품질이 저하되고, 모델 성능이 나빠지며, 결과 해석에도 오류가 발생합니다. 따라서 적절한 방법(삭제, 대체, 예측 모델 등)을 통해 결측치를 처리하는 것이 중요합니다. 또한 결측치가 무작위로 발생했는지, 패턴이 있는지 확인하기 위해 Missingno 라이브러리를 사용해 결측치 히트맵을 시각화할 수 있습니다.
>
> - 삭제: 결측값이 많지 않은 경우, 결측값이 있는 행이나 열을 삭제할 수 있습니다. 데이터 손실에 유의해야 합니다.   
> - 대체: 결측치를 평균, 중앙값, 최빈값 등으로 대체하거나, KNN Imputation와 같은 기법을 통해 예측하여 채웁니다. 이는 데이터의 일관성을 유지하는 데 유용합니다.   
> - 예측 모델: 머신러닝 모델을 사용해 결측치를 예측하고 채울 수 있습니다. 이는 특히 결측 패턴이 복잡할 때 유용합니다. RandomForest Regressor 등이 그 예시입니다.
   
2. 데이터 스케일링  
> - 표준화(Standardization): 데이터의 평균을 0, 표준편차를 1로 맞추는 방법입니다. 특히, SVM, KNN, K-Means 같은 거리 기반 모델에 효과적입니다.  
> - 정규화(Normalization): 데이터를 0과 1 사이로 스케일링하여 변환합니다. 일반적으로 최소값을 0, 최대값을 1로 설정하는 Min-Max 스케일링을 사용합니다. 정규화는 신경망 모델에 적합합니다.  
> - 로버스트 스케일링(Robust Scaling): 이상치에 민감하지 않도록 중앙값과 사분위 범위를 사용하여 스케일링합니다. 이상치가 많을 때 유용합니다.

3. 인코딩   
> - 레이블 인코딩(Label Encoding): 범주형 변수를 정수로 변환합니다. 예를 들어, ‘남성’을 0, ‘여성’을 1로 변환할 수 있습니다. 그러나 레이블 간 순서가 없을 때는 부적절할 수 있습니다.   
> - 원-핫 인코딩(One-Hot Encoding): 각 카테고리를 이진 벡터로 변환하여 순서의 의미를 제거합니다. 예를 들어, ‘빨강’, ‘파랑’, ‘초록’이라는 카테고리를 [1, 0, 0], [0, 1, 0], [0, 0, 1]과 같이 변환합니다.
> - 임베딩(Embedding): 주로 자연어 처리에서 사용하며, 고차원 벡터로 카테고리를 변환해 의미와 패턴을 보존합니다. 인공신경망에 적합합니다.

4. 이상치 처리   
> - 이상치 탐지 및 제거: 이상치는 데이터 분포를 왜곡할 수 있으므로 박스 플롯, IQR, Z-점수 등을 사용하여 이상치를 탐지하고 제거합니다.    
> - 대체: 극단값을 평균이나 중앙값 등의 특정 값으로 대체합니다.   
> - 변환(Transformation): 로그 변환, 제곱근 변환 등을 적용하여 이상치의 영향을 줄일 수 있습니다.     

5. 특성 엔지니어링(Feature Engineering)   
> - 특성 생성: 기존 데이터를 이용해 새로운 특성을 생성합니다. 예를 들어, 날짜 데이터를 기반으로 ‘연도’, ‘월’, ‘일’ 등의 특성을 추출할 수 있습니다.   
> - 차원 축소: PCA, LDA 등 차원 축소 기법을 사용해 불필요한 특성을 제거하고 모델의 효율성을 높입니다.   
> - 다항식 특성(Polynomial Features): 특정 변수의 상호작용을 반영하기 위해 변수 간의 곱이나 제곱을 생성하여 추가합니다. 예를 들어, x와 y라는 특성의 제곱과 곱을 생성하여 모델에 반영할 수 있습니다.

6. 데이터 분리(Data Splitting)   
> - 훈련/검증/테스트 세트 분리: 데이터를 훈련, 검증, 테스트 세트로 나눠서 모델의 성능을 평가합니다. 일반적으로 70:15:15 또는 80:10:10 비율로 나눕니다.   
> - 교차 검증(Cross-Validation): 데이터를 여러 번 훈련과 테스트로 나누어 모델의 일반화 성능을 평가하는 방법입니다. K-교차 검증(K-fold Cross-Validation)이 가장 많이 사용됩니다.

7. 데이터 증강(Data Augmentation)
> 
> - 이미지 데이터 증강: 회전, 크기 조정, 플립 등 다양한 변형을 통해 데이터 다양성을 높여 모델이 다양한 패턴을 학습할 수 있도록 합니다.    
> - 텍스트 데이터 증강: 문장 내 단어 순서 변경, 동의어 교체 등을 통해 텍스트 데이터를 증가시키는 방법입니다.    
> - 시간 시계열 데이터 증강: 시계열 데이터의 일부 구간을 샘플링하거나 노이즈를 추가하는 방법이 있습니다.    
