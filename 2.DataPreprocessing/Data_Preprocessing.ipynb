{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "Uh5Ef1gc0ijX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터를 변환하는 함수\n",
        "- 데이터를 학습에 사용할 수 있도록 데이터 변환\n",
        "- Smiles(문자형) -> 분자지분(166 bits)\n",
        "\n",
        "\n",
        "smiles2fing 함수는 SMILES 형식의 문자열 리스트를 입력받아, 각 분자에 대한 MACCS 키 기반의 분자 fingerprint를 생성하고 처리합니다.\n",
        "\n",
        "smiles2fing 함수의 동작 과정은 아래와 같습니다.\n",
        "\n",
        "smiles2fing 함수의 입력으로 받아온 SMILES 문자열 리스트(smiles)는 Chem.MolFromSmiles 함수를 통해 각 문자열에 해당하는 분자 객체로 반환됩니다.\n",
        "\n",
        "Chem.MolFromSmiles에 의해 반환되지 못하는 문자열은, None으로 반환됩니다.\n",
        "None으로 반환된 모든 문자열들의 인덱스를 새로운 리스트 'ms_none_idx'에 저장합니다.\n",
        "\n",
        "ms_tmp에서 None이 아닌(분자 객체로 성공적으로 반환된 친구들) 분자 객체만을 필터링하여 새로운 리스트 'ms'에 저장합니다.\n",
        "\n",
        "ms에 속하는 모든 객체를 각각 MACCSkeys.GenMACCSKeys 함수를 통해 MACCS키로 변환하고, 이를 새로운 리스트 'maccs'에 저장합니다.\n",
        "\n",
        "maccs의 모든 각 원소를 이진 문자열로 변환하고, 이를 새로운 리스트 'maccs_bit'에 저장합니다.\n",
        "\n",
        "maccs_bit를 pandas 데이터프레임으로 변환합니다.\n",
        "\n",
        "pandas.DataFrame을 통해 생성된 데이터프레임은 'maccs'라는 하나의 열을 가집니다.\n",
        "str.split 메서드를 사용해 이진 문자열을 개별 문자 단위로 분할합니다.\n",
        "\n",
        "expand 옵션이 True이기 때문에 분할된 개별 문자가 데이터프레임의 별도 열로 확장됩니다.\n",
        "단, 최대 167개의 문자로 분할될 수 있습니다.\n",
        "이진 문자열을 분할하면 첫 번째 열은 항상 비어있는 값으로 채워집니다. 해당 열은 불필요하기 때문에 데이터프레임에서 제거합니다.\n",
        "\n",
        "데이터프레임의 열의 이름을 maccs_1, maccs_2, maccs_3, ..., maccs_167로 지정합니다.\n",
        "\n",
        "데이터프레임의 데이터 타입을 정수로 변환하고, 인덱스를 재설정합니다.\n",
        "\n",
        "함수의 output으로 None으로 반환된 문자열들의 인덱스와 각종 처리가 수행된 fingerprint 데이터프레임을 반환합니다."
      ],
      "metadata": {
        "id": "bRq1kvth0mbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smiles2fing(smiles):\n",
        "    ms_tmp = [Chem.MolFromSmiles(i) for i in smiles]\n",
        "    ms_none_idx = [i for i in range(len(ms_tmp)) if ms_tmp[i] == None]\n",
        "\n",
        "    ms = list(filter(None, ms_tmp))\n",
        "\n",
        "    maccs = [MACCSkeys.GenMACCSKeys(i) for i in ms]\n",
        "    maccs_bit = [i.ToBitString() for i in maccs]\n",
        "\n",
        "    fingerprints = pd.DataFrame({'maccs': maccs_bit})\n",
        "    fingerprints = fingerprints['maccs'].str.split(pat = '', n = 167, expand = True)\n",
        "    fingerprints.drop(fingerprints.columns[0], axis = 1, inplace = True)\n",
        "\n",
        "    colname = ['maccs_' + str(i) for i in range(1, 168)]\n",
        "    fingerprints.columns = colname\n",
        "    fingerprints = fingerprints.astype(int).reset_index(drop = True)\n",
        "\n",
        "    return ms_none_idx, fingerprints"
      ],
      "metadata": {
        "id": "yaqhAGzo1CpR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "JIMJpHVD1CyW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3n_2WLWA0HfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3bcb98-27e6-4ae1-d09e-3795b45b289c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NR-AR  NR-AR-LBD  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  \\\n",
            "0    0.0        0.0     1.0           NaN    NaN        0.0            0.0   \n",
            "1    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
            "2    NaN        NaN     NaN           NaN    NaN        NaN            NaN   \n",
            "3    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
            "4    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
            "\n",
            "   SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53    mol_id  \\\n",
            "0     1.0       0.0     0.0     0.0     0.0   TOX3021   \n",
            "1     NaN       0.0     NaN     0.0     0.0   TOX3020   \n",
            "2     0.0       NaN     0.0     NaN     NaN   TOX3024   \n",
            "3     NaN       0.0     NaN     0.0     0.0   TOX3027   \n",
            "4     0.0       0.0     0.0     0.0     0.0  TOX20800   \n",
            "\n",
            "                                              smiles  \n",
            "0                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1  \n",
            "1                          CCN1C(=O)NC(c2ccccc2)C1=O  \n",
            "2  CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...  \n",
            "3                    CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C  \n",
            "4                          CC(O)(P(=O)(O)O)P(=O)(O)O  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[10:24:13] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        }
      ],
      "source": [
        "# 라이브러리 호출\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# rdkit: 화학 정보학과 기계 학습을 위한 오픈 소스 화학 정보학 소프트웨어 툴킷입니다.\n",
        "\n",
        "try:\n",
        "# rdkit.Chem: 분자와 관련된 기본적인 기능과 클래스를 제공합니다.\n",
        "# rdkit.Chem.MACCSkys: 화합물의 분자 지문을 생성하는 데 사용되는 방법 중 하나입니다.\n",
        "    from rdkit import Chem\n",
        "    from rdkit.Chem import MACCSkeys\n",
        "\n",
        "# rdkit 라이브러리가 호출되지 않을 시, 라이브러리 설치 후 재호출\n",
        "except:\n",
        "    import sys\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rdkit-pypi\"])\n",
        "    # subprocess.check_call([sys.executable, \"-m\", \"conda\", \"install\", \"rdkit\", \"-c conda-forge\"])\n",
        "\n",
        "    from rdkit import Chem\n",
        "    from rdkit.Chem import MACCSkeys\n",
        "\n",
        "# 데이터를 불러오기 위한 경로 설정\n",
        "folder = '.'\n",
        "file = 'tox21.xlsm' # 12개의 label과 SMILE가 존재하는 데이터 파일\n",
        "cur_sheet = 'Tox21'\n",
        "\n",
        "# pandas 라이브러리를 통해 csv파일을 불러오기\n",
        "data = pd.read_excel(f'{folder}/{file}', sheet_name= cur_sheet)\n",
        "print(data.head())  # 데이터 일부분을 출력\n",
        "# 가공하고자 하는 데이터를 따로 추출\n",
        "smiles = data['smiles'].to_numpy()\n",
        "# smiles2fing 함수를 통해 데이터 변환 실시\n",
        "_, fings = smiles2fing(smiles)  # fings 변수에 변환된 features가 저장되어 있음\n",
        "\n",
        "# 학습에 사용할 수 있도록 데이터셋 생성\n",
        "mol_id = data['mol_id']     # 이름\n",
        "labels = data.iloc[:,0:12]  # label\n",
        "dataset = pd.concat([mol_id, fings, labels], axis= 1)   # features\n",
        "\n",
        "# 생성한 데이터셋을 csv파일로 내보내기\n",
        "dataset.to_csv(f'{folder}/Tox21_Dataset.csv', index= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Test Split"
      ],
      "metadata": {
        "id": "SWDPZpqe2E_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# 데이터 파일 경로 설정\n",
        "folder = '.'\n",
        "file = 'Tox21_Dataset.csv'\n",
        "path = f'{folder}/{file}'\n",
        "\n",
        "# 데이터 분리를 하기 위한 하이퍼 파라미터 설정\n",
        "label_idx = 0       # 학습에 사용하고 하는 label 선택 - 0 ~ 11중 선택 가능 | 0 -> NR-AR, 11 -> SR-p53\n",
        "train_size = 0.8    # train과 test의 비율을 설정\n",
        "\n",
        "# 데이터 파일 불러오기\n",
        "df = pd.read_csv(path)\n",
        "feature = df.iloc[:,2:168]          # Features (166개)\n",
        "label = df.iloc[:,168+label_idx]    # label\n",
        "\n",
        "# label 기준으로 결측값(NaN)인 데이터 제거하기\n",
        "idx_none = df[df.iloc[:,168 + label_idx].notna()].index # 결측값이 아닌 데이터의 index\n",
        "feature = df.iloc[idx_none, 1:168]          # 필요한 데이터의 feature만 가져오기\n",
        "label = df.iloc[idx_none, 168+label_idx]    # 필요한 데이터의 label만 가져오기\n",
        "\n",
        "# 사이킷런에서 제공하는 함수를 이용하여 train과 test 데이터 분리하기\n",
        "    # stratify : label을 기준으로 train과 test의 분포가 동일하도록 분리함\n",
        "train_x, test_x, train_y, test_y = train_test_split(feature, label, train_size= train_size, stratify= label)\n",
        "\n",
        "# 분리한 결과 확인하기\n",
        "print('train dataset')\n",
        "print(f'\\tX : {train_x.shape}, Y : {train_y.shape}')\n",
        "print('test dataset')\n",
        "print(f'\\tX : {test_x.shape}, Y : {test_y.shape}')"
      ],
      "metadata": {
        "id": "3C3iZ9XG2FLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dfbec34-c0c0-4b8d-9d68-f35b9bfac1d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train dataset\n",
            "\tX : (5812, 167), Y : (5812,)\n",
            "test dataset\n",
            "\tX : (1453, 167), Y : (1453,)\n"
          ]
        }
      ]
    }
  ]
}