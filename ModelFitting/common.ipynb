{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import json**\n",
    "\n",
    "json은 JSON 데이터를 읽고 쓸 수 있게 해주는 표준 라이브러리입니다.\n",
    "\n",
    "**import sklearn**\n",
    "\n",
    "sklearn(scikit learn)은 파이썬 머신러닝 라이브러리로 다양한 머신러닝 알고리즘을 제공합니다.\n",
    "\n",
    "**import numpy as np**\n",
    "\n",
    "배열을 처리하는 라이브러리로 다차원 배열의 빠른 처리와 배열 broadcasting 기능, 선형 변환 기능을 사용할 수 있습니다. numpy 라이브러리 기능을 사용할 때, 편의성을 위해 np로 호출할 수 있도록 as np를 붙여줍니다.\n",
    "\n",
    "**import pandas as pd**\n",
    "\n",
    "Pandas는 Series와 DataFrame 자료형을 사용하여 데이터를 처리하는 파이썬 데이터 분석 라이브러리입니다. pandas 함수 호출을 간편하게 처리하기 위해 as pd를 사용합니다.\n",
    "\n",
    "**from tqdm import tqdm**\n",
    "\n",
    "tqdm은 파이썬의 반복문의 진행 상황을 시각적으로 보여주는 라이브러리입니다.\n",
    "\n",
    "**from itertools import product**\n",
    "\n",
    "itertools.product를 사용하여 반복 가능한 변수들의 곱을 계산할 수 있도록 해줍니다. 즉, 반복 가능한 변수들 간의 모든 조합을 생상하는 데 사용할 수 있습니다.\n",
    "\n",
    "**from collections.abc import Iterable**\n",
    "\n",
    "Iterable은 객체가 반복 가능한지를 확인할 수 있도록 해주는 클래스입니다.\n",
    "\n",
    "**from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit**\n",
    "\n",
    "StratifiedKFold는 데이터를 계층화된 방법으로 분할하여 교차 검증을 수행할 수 있도록 해주는 클래스입니다.\n",
    "StratifiedShuffleSplit는 불균형 분포를 위한 교차 검증을 위해서 계층화된 방식으로 무작위 분할을 통해 Train/Test Set을 생성하는 클래스입니다.\n",
    "\n",
    "**from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, f1_score**\n",
    "\n",
    "Precision, Recall, Accurcay, ROC_AUC 점수모델의 성능을 평가하기 위한 다양한 메트릭을 계산하는 함수들을 import합니다.\n",
    "\n",
    "**from sklearn.cross_decomposition import PLSRegression**\n",
    "\n",
    "부분 최소 제곱 회귀함수를 수행하는 클래스입니다. 고차원 데이터를 사용하여 선형 회귀를 진행하기 위한 클래스입니다.\n",
    "\n",
    "**from imblearn.over_sampling import SMOTE**\n",
    "\n",
    "소수 클래스 집합의 데이터를 오버샘플링하기 위한 SMOTE 기법을 사용하는 클래스입니다. 불균형 데이터셋을 처리하기 위해서 소수 클래스의 샘플을 합성하여 추가하는 SMOTE 방식을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, \n",
    "    StratifiedShuffleSplit\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_split 함수는 데이터를 분할하는 함수입니다. scikit-learn의 StratifiedShuffleSplit을 사용해 데이터를 분할합니다. \n",
    "- StratifiedShuffleSplit은 데이터를 섞은 후에 나누는 것이 아니라, 데이터를 나눈 후에 섞는 방식으로 동작합니다. \n",
    "\n",
    "\n",
    "함수는 아래와 같은 과정으로 동작합니다.\n",
    "1. StratifiedShuffleSplit의 객체, sss를 생성합니다.\n",
    "- sss는 데이터를 1번 분할하고, 테스트 데이터의 비율을 20%로 설정한다는 정보가 담겨있습니다.\n",
    "\n",
    "2. sss.split(X, y)를 호출합니다.\n",
    "- X는 데이터의 feature, y는 데이터의 label입니다.\n",
    "- split 함수는 X와 y를 test_size 비율로 나눈 후에, train_idx와 test_idx를 반환합니다.\n",
    "- train_idx와 test_idx는 각각 train 데이터와 test 데이터에 사용할 데이터의 인덱스입니다.\n",
    "\n",
    "3. train_idx와 test_idx를 사용해 train_x, test_x, train_y, test_y에 해당되는 데이터를 저장합니다.\n",
    "- reset_index(drop = True)는 인덱스를 0부터 다시 시작하도록 설정함을 의미합니다.\n",
    "\n",
    "4. train_x, test_x, train_y, test_y를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y, seed):\n",
    "    sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = seed)\n",
    "    \n",
    "    for train_idx, test_idx in sss.split(X, y):\n",
    "        train_x = X.iloc[train_idx].reset_index(drop = True)\n",
    "        train_y = y.iloc[train_idx].reset_index(drop = True)\n",
    "        test_x = X.iloc[test_idx].reset_index(drop = True)\n",
    "        test_y = y.iloc[test_idx].reset_index(drop = True)\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter_grid는 하이퍼파라미터의 dictionary를 받아서 가능한 모든 조합의 하이퍼파라미터의 리스트를 생성하고 이를 반환합니다.\n",
    "\n",
    "\n",
    "함수의 동작 과정은 아래와 같습니다\n",
    "1. 들어온 입력이 dictionary가 아니면 TypeError를 발생시킵니다.\n",
    "2. dictionary의 value가 iterable이 아니면 TypeError를 발생시킵니다.\n",
    "    - iterable이란 list, tuple, set, dict, str 와 같이 맴버들을 한 번에 한 개씩 반환할 수 있는 객체를 말합니다.\n",
    "    - int, float, bool 등의 객체는 iterable 하지 않습니다.\n",
    "\n",
    "3. dictionary의 항목들을 key를 기준으로 정렬합니다.\n",
    "4. dictionary의 key와 value를 각각 keys와 values에 저장합니다.\n",
    "5. itertools.product를 사용하여 values의 모든 조합을 생성합니다.\n",
    "6. 생성된 조합을 dictionary로 변환하여 params_grid에 저장합니다.\n",
    "7. params_grid를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_grid(param_dict):\n",
    "    if not isinstance(param_dict, dict):\n",
    "        raise TypeError('Parameter grid is not a dict ({!r})'.format(param_dict))\n",
    "    \n",
    "    if isinstance(param_dict, dict):\n",
    "        for key in param_dict:\n",
    "            if not isinstance(param_dict[key], Iterable):\n",
    "                raise TypeError('Parameter grid value is not iterable '\n",
    "                                '(key={!r}, value={!r})'.format(key, param_dict[key]))\n",
    "    \n",
    "    items = sorted(param_dict.items())\n",
    "    keys, values = zip(*items)\n",
    "    \n",
    "    params_grid = []\n",
    "    for v in product(*values):\n",
    "        params_grid.append(dict(zip(keys, v))) \n",
    "    \n",
    "    return params_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiclass_cross_validation은 모델과 데이터를 받아서 5-fold cross validation을 수행하고, 각 fold에 대한 평균 precision, recall, f1, accuracy를 계산하여 반환하는 함수입니다.\n",
    "\n",
    "k-fold cross validation을 수행하기 위해서 StratifiedKFold를 사용합니다. \n",
    "- StratifiedKFold는 각 fold에 대해서 클래스의 비율이 유지되도록 데이터를 분할합니다. \n",
    "\n",
    "평가를 수행하는 metric은 아래와 같습니다.\n",
    "1. precision\n",
    "2. recall\n",
    "3. f1\n",
    "4. accuracy\n",
    "\n",
    "각 fold에 대한 평가를 저장하기 위한 변수(리스트)를 선언합니다.\n",
    "\n",
    "\n",
    "skf.split(x, y)는 x와 y를 5-fold로 분할한 후, 각 fold에 대한 train index와 validation index를 반환하는 함수입니다.\n",
    "해당되는 index를 사용하여 train_x, train_y, val_x, val_y를 추출하고, 모델을 학습시킵니다.\n",
    "\n",
    "\n",
    "PLSRegression은 다중 클래스 분류를 지원하지 않기 때문에, 별도로 one-hot encoding을 수행합니다.\n",
    "- 예측값을 처리할 때, argmax를 사용하여 가장 높은 확률을 가진 클래스를 선택합니다.\n",
    "\n",
    "\n",
    "학습된 모델을 사용하여 train_x, val_x에 대한 예측값을 구하고, 각 metric을 계산합니다.\n",
    "- metric을 계산할 때, average = 'macro'로 설정합니다.\n",
    "    - average = 'macro'는 클래스별로 metric을 계산한 후, 평균을 계산하는 방식입니다.\n",
    "\n",
    "\n",
    "반환될 result는 다음과 형태를 가집니다.\n",
    "\n",
    "{\n",
    "    'train_precision': 0.95,\n",
    "    'train_recall': 0.94,\n",
    "    'train_f1': 0.94,\n",
    "    'train_accuracy': 0.95,\n",
    "    'val_precision': 0.92,\n",
    "    'val_recall': 0.91,\n",
    "    'val_f1': 0.91,\n",
    "    'val_accuracy': 0.92\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_cross_validation(model, x, y, seed):\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)\n",
    "    \n",
    "    metrics = ['precision', 'recall', 'f1', 'accuracy']\n",
    "    \n",
    "    train_metrics = list(map(lambda x: 'train_' + x, metrics))\n",
    "    val_metrics = list(map(lambda x: 'val_' + x, metrics))\n",
    "    \n",
    "    train_precision = []\n",
    "    train_recall = []\n",
    "    train_f1 = []\n",
    "    train_accuracy = []\n",
    "    \n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_f1 = []\n",
    "    val_accuracy = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(x, y):\n",
    "        train_x, train_y = x.iloc[train_idx], y.iloc[train_idx]\n",
    "        val_x, val_y = x.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        if type(model) == sklearn.cross_decomposition._pls.PLSRegression:\n",
    "            onehot_train_y = pd.get_dummies(train_y)\n",
    "            \n",
    "            model.fit(train_x, onehot_train_y)\n",
    "            \n",
    "            train_pred = np.argmax(model.predict(train_x), axis = 1)\n",
    "            val_pred = np.argmax(model.predict(val_x), axis = 1)\n",
    "            \n",
    "        else:\n",
    "            model.fit(train_x, train_y)\n",
    "            \n",
    "            train_pred = model.predict(train_x)\n",
    "            val_pred = model.predict(val_x)\n",
    "        \n",
    "        train_precision.append(precision_score(train_y, train_pred, average = 'macro'))\n",
    "        train_recall.append(recall_score(train_y, train_pred, average = 'macro'))\n",
    "        train_f1.append(f1_score(train_y, train_pred, average = 'macro'))\n",
    "        train_accuracy.append(accuracy_score(train_y, train_pred))\n",
    "\n",
    "        val_precision.append(precision_score(val_y, val_pred, average = 'macro'))\n",
    "        val_recall.append(recall_score(val_y, val_pred, average = 'macro'))\n",
    "        val_f1.append(f1_score(val_y, val_pred, average = 'macro'))\n",
    "        val_accuracy.append(accuracy_score(val_y, val_pred))\n",
    "        \n",
    "    result = dict(zip(train_metrics + val_metrics, \n",
    "                      [np.mean(train_precision), np.mean(train_recall), np.mean(train_f1), np.mean(train_accuracy), \n",
    "                       np.mean(val_precision), np.mean(val_recall), np.mean(val_f1), np.mean(val_accuracy)]))\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_validation(model, x, y, seed):\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)\n",
    "    \n",
    "    metrics = ['precision', 'recall', 'f1', 'accuracy', 'auc']\n",
    "    \n",
    "    train_metrics = list(map(lambda x: 'train_' + x, metrics))\n",
    "    val_metrics = list(map(lambda x: 'val_' + x, metrics))\n",
    "    \n",
    "    train_precision = []\n",
    "    train_recall = []\n",
    "    train_f1 = []\n",
    "    train_accuracy = []\n",
    "    train_auc = []\n",
    "    \n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_f1 = []\n",
    "    val_accuracy = []\n",
    "    val_auc = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(x, y):\n",
    "        train_x, train_y = x.iloc[train_idx], y.iloc[train_idx]\n",
    "        val_x, val_y = x.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        if type(model) == sklearn.cross_decomposition._pls.PLSRegression:\n",
    "            model.fit(train_x, train_y)\n",
    "            \n",
    "            train_pred_score = model.predict(train_x)\n",
    "            train_pred = np.where(train_pred_score < 0.5, 0, 1).reshape(-1)\n",
    "            \n",
    "            val_pred_score = model.predict(val_x)\n",
    "            val_pred = np.where(val_pred_score < 0.5, 0, 1).reshape(-1)\n",
    "            \n",
    "        else:\n",
    "            model.fit(train_x, train_y)\n",
    "            \n",
    "            train_pred = model.predict(train_x)\n",
    "            train_pred_score = model.predict_proba(train_x)[:, 1]\n",
    "            \n",
    "            val_pred = model.predict(val_x)\n",
    "            val_pred_score = model.predict_proba(val_x)[:, 1]\n",
    "        \n",
    "        train_precision.append(precision_score(train_y, train_pred))\n",
    "        train_recall.append(recall_score(train_y, train_pred))\n",
    "        train_f1.append(f1_score(train_y, train_pred))\n",
    "        train_accuracy.append(accuracy_score(train_y, train_pred))\n",
    "        train_auc.append(roc_auc_score(train_y, train_pred_score))\n",
    "\n",
    "        val_precision.append(precision_score(val_y, val_pred))\n",
    "        val_recall.append(recall_score(val_y, val_pred))\n",
    "        val_f1.append(f1_score(val_y, val_pred))\n",
    "        val_accuracy.append(accuracy_score(val_y, val_pred))\n",
    "        val_auc.append(roc_auc_score(val_y, val_pred_score))\n",
    "\n",
    "    result = dict(zip(train_metrics + val_metrics, \n",
    "                      [np.mean(train_precision), np.mean(train_recall), np.mean(train_f1), np.mean(train_accuracy), np.mean(train_auc), \n",
    "                       np.mean(val_precision), np.mean(val_recall), np.mean(val_f1), np.mean(val_accuracy), np.mean(val_auc)]))\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binary_smote_cross_validation 함수는 이진 분류 문제에 대해 SMOTE 기법을 활용하여 교차 검증을 수행하는 함수입니다. 모델(model), 특성 데이터(x), 타겟 데이터(y), 시드 값(seed), 추가 인자(args)를 입력으로 받습니다.\n",
    "\n",
    "앞서 multiclass_cross_valdation 함수에서 사용했던 StratifiedKFold를 사용하여 데이터를 5개의 폴드로 나눕니다. 이를 통해 각 클래스에 대한 비율을 유지한 체로 폴드를 생성됩니다.\n",
    "\n",
    "이후 각 폴드를 구성하는 데이터 셋에 대해 SMOTE 기법을 사용하여 훈련 데이터의 소수 클래스를 오버샘플링합니다. 이를 통해 불균형 데이터섯에 대한 처리를 진행할 수 있습니다.\n",
    "\n",
    "이후, multiclass_cross_validation에서 사용한 방식과 동일하게, 각 폴드에서 모델을 훈련시키고, 훈련 및 검증 데이터에 대한 여러 평가 지표(정밀도, 재현율, F1 점수, 정확도, AUC)를 계산합니다. 또한, 각 폴드의 평가 지표들의 평균을 계산하여 최종 결과를 사전 형태로 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_smote_cross_validation(model, x, y, seed, args):\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)\n",
    "    \n",
    "    metrics = ['precision', 'recall', 'f1', 'accuracy', 'auc']\n",
    "    \n",
    "    train_metrics = list(map(lambda x: 'train_' + x, metrics))\n",
    "    val_metrics = list(map(lambda x: 'val_' + x, metrics))\n",
    "    \n",
    "    train_precision = []\n",
    "    train_recall = []\n",
    "    train_f1 = []\n",
    "    train_accuracy = []\n",
    "    train_auc = []\n",
    "    \n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_f1 = []\n",
    "    val_accuracy = []\n",
    "    val_auc = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(x, y):\n",
    "        train_x, train_y = x.iloc[train_idx], y.iloc[train_idx]\n",
    "        val_x, val_y = x.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        smote = SMOTE(random_state = args.smoteseed, k_neighbors = args.neighbor)\n",
    "        train_x, train_y = smote.fit_resample(train_x, train_y)\n",
    "        \n",
    "        if type(model) == sklearn.cross_decomposition._pls.PLSRegression:\n",
    "            model.fit(train_x, train_y)\n",
    "            \n",
    "            train_pred_score = model.predict(train_x)\n",
    "            train_pred = np.where(train_pred_score < 0.5, 0, 1).reshape(-1)\n",
    "            \n",
    "            val_pred_score = model.predict(val_x)\n",
    "            val_pred = np.where(val_pred_score < 0.5, 0, 1).reshape(-1)\n",
    "            \n",
    "        else:\n",
    "            model.fit(train_x, train_y)\n",
    "            \n",
    "            train_pred = model.predict(train_x)\n",
    "            train_pred_score = model.predict_proba(train_x)[:, 1]\n",
    "            \n",
    "            val_pred = model.predict(val_x)\n",
    "            val_pred_score = model.predict_proba(val_x)[:, 1]\n",
    "        \n",
    "        train_precision.append(precision_score(train_y, train_pred))\n",
    "        train_recall.append(recall_score(train_y, train_pred))\n",
    "        train_f1.append(f1_score(train_y, train_pred))\n",
    "        train_accuracy.append(accuracy_score(train_y, train_pred))\n",
    "        train_auc.append(roc_auc_score(train_y, train_pred_score))\n",
    "\n",
    "        val_precision.append(precision_score(val_y, val_pred))\n",
    "        val_recall.append(recall_score(val_y, val_pred))\n",
    "        val_f1.append(f1_score(val_y, val_pred))\n",
    "        val_accuracy.append(accuracy_score(val_y, val_pred))\n",
    "        val_auc.append(roc_auc_score(val_y, val_pred_score))\n",
    "\n",
    "    result = dict(zip(train_metrics + val_metrics, \n",
    "                      [np.mean(train_precision), np.mean(train_recall), np.mean(train_f1), np.mean(train_accuracy), np.mean(train_auc), \n",
    "                       np.mean(val_precision), np.mean(val_recall), np.mean(val_f1), np.mean(val_accuracy), np.mean(val_auc)]))\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용되지 않는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CV(x, y, model, params, seed):\n",
    "#     skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)\n",
    "    \n",
    "#     metrics = ['precision', 'recall', 'f1', 'accuracy']\n",
    "    \n",
    "#     train_metrics = list(map(lambda x: 'train_' + x, metrics))\n",
    "#     val_metrics = list(map(lambda x: 'val_' + x, metrics))\n",
    "    \n",
    "#     train_precision = []\n",
    "#     train_recall = []\n",
    "#     train_f1 = []\n",
    "#     train_accuracy = []\n",
    "    \n",
    "#     val_precision = []\n",
    "#     val_recall = []\n",
    "#     val_f1 = []\n",
    "#     val_accuracy = []\n",
    "    \n",
    "#     for train_idx, val_idx in skf.split(x, y):\n",
    "#         train_x, train_y = x.iloc[train_idx], y.iloc[train_idx]\n",
    "#         val_x, val_y = x.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "#         try:\n",
    "#             clf = model(random_state = seed, **params)\n",
    "#         except:\n",
    "#             clf = model(**params)\n",
    "        \n",
    "        \n",
    "#         if model == sklearn.cross_decomposition._pls.PLSRegression:\n",
    "#             onehot_train_y = pd.get_dummies(train_y)\n",
    "            \n",
    "#             clf.fit(train_x, onehot_train_y)\n",
    "            \n",
    "#             train_pred = np.argmax(clf.predict(train_x), axis = 1)\n",
    "#             val_pred = np.argmax(clf.predict(val_x), axis = 1)\n",
    "            \n",
    "#         else:\n",
    "#             clf.fit(train_x, train_y)\n",
    "            \n",
    "#             train_pred = clf.predict(train_x)\n",
    "#             val_pred = clf.predict(val_x)\n",
    "        \n",
    "#         train_precision.append(precision_score(train_y, train_pred, average = 'macro'))\n",
    "#         train_recall.append(recall_score(train_y, train_pred, average = 'macro'))\n",
    "#         train_f1.append(f1_score(train_y, train_pred, average = 'macro'))\n",
    "#         train_accuracy.append(accuracy_score(train_y, train_pred))\n",
    "\n",
    "#         val_precision.append(precision_score(val_y, val_pred, average = 'macro'))\n",
    "#         val_recall.append(recall_score(val_y, val_pred, average = 'macro'))\n",
    "#         val_f1.append(f1_score(val_y, val_pred, average = 'macro'))\n",
    "#         val_accuracy.append(accuracy_score(val_y, val_pred))\n",
    "        \n",
    "#     result = dict(zip(['params'] + train_metrics + val_metrics, \n",
    "#                       [params] + [np.mean(train_precision), \n",
    "#                                   np.mean(train_recall), \n",
    "#                                   np.mean(train_f1), \n",
    "#                                   np.mean(train_accuracy), \n",
    "#                                   np.mean(val_precision), \n",
    "#                                   np.mean(val_recall), \n",
    "#                                   np.mean(val_f1), \n",
    "#                                   np.mean(val_accuracy)]))\n",
    "    \n",
    "#     return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metric_mean 함수는 주어진 데이터에서 특정 메트릭의 평균값을 계산하는 함수입니다.\n",
    "\n",
    "data 매개변수는 평가 메트릭이 저장된 데이터 구조(예: 사전)를 받습니다.\n",
    "\n",
    "metric 매개변수를 통해 계산하고자 하는 특정 메트릭의 이름을 문자열로 받아 data[metric].items()를 통해 해당 메트릭에 대한 모든 값들을 순회합니다.\n",
    "\n",
    "각 값에 대해 numpy의 mean 함수를 사용하여 평균을 계산하고, 이를 리스트로 변환합니다.\n",
    "\n",
    "결과적으로, 입력된 메트릭에 대한 평균값들의 리스트를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_mean(data, metric: str):\n",
    "    mean_per_hp = list(map(lambda x: np.mean(x[1]), data[metric].items()))\n",
    "    return mean_per_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print_best_param은 val_result에서 metric에 해당하는 평균값이 가장 높은 파라미터를 반환하는 함수입니다.\n",
    "\n",
    "\n",
    "함수는 아래의 과정으로 동작합니다.\n",
    "1. val_result에서 metric에 해당하는 평균값을 구합니다.\n",
    "2. 평균값이 가장 높은 파라미터의 인덱스를 구합니다.\n",
    "3. val_result에서 해당 인덱스에 해당하는 파라미터를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_param(val_result, metric: str):\n",
    "    \n",
    "    mean_list = metric_mean(val_result, metric)\n",
    "    max_idx = mean_list.index(max(mean_list))\n",
    "    \n",
    "    best_param = val_result['model'][f'model{max_idx}']\n",
    "    \n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_val_result 함수는 JSON 형식의 검증 결과를 불러오는 함수입니다.\n",
    "\n",
    "path, tg_num, inhale_type, model 매개변수들은 파일 경로와 파일 이름을 결정하는 데 사용되며 is_smote 매개변수는 SMOTE 기법을 사용한 결과를 불러올지, 사용하지 않은 결과를 불러올 지 결정해줍니다.\n",
    "\n",
    "SMOTE 사용 여부(is_smote)에 따라 다른 파일 경로에서 JSON 파일을 불러옵니다. try-except 블록을 통해 첫 번째 try에서 파일을 열지 못하면, except 블록에서 다른 경로의 파일을 시도합니다.\n",
    "\n",
    "JSON 파일의 내용은 json.load 함수를 사용하여 파이썬 객체로 변환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_val_result(path: str, tg_num: int, inhale_type: str, model: str, is_smote = True):\n",
    "    if is_smote:\n",
    "        try:\n",
    "            with open(f'{path}/tg{tg_num}_val_results/binary_smote5/{inhale_type}_{model}.json', 'r') as file:\n",
    "                val_result = json.load(file)\n",
    "        except:\n",
    "            with open(f'{path}tg{tg_num}_val_results/binary_smote5/{inhale_type}_{model}.json', 'r') as file:\n",
    "                val_result = json.load(file)\n",
    "    else:\n",
    "        try:\n",
    "            with open(f'{path}/tg{tg_num}_val_results/binary/{inhale_type}_{model}.json', 'r') as file:\n",
    "                val_result = json.load(file)\n",
    "        except:\n",
    "            with open(f'{path}tg{tg_num}_val_results/binary/{inhale_type}_{model}.json', 'r') as file:\n",
    "                val_result = json.load(file)\n",
    "    \n",
    "    return val_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용되지 않는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_best_param(path: str, tg_num: int, inhale_type: str, model: str, metric: str):\n",
    "#     data = load_val_result(path, tg_num, inhale_type, model)\n",
    "    \n",
    "#     mean_list = metric_mean(data, 'f1')\n",
    "#     max_idx = mean_list.index(max(mean_list))\n",
    "    \n",
    "#     best_param = data['model'][f'model{max_idx}']\n",
    "    \n",
    "#     return best_param"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
