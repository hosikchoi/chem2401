{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMR3N0m5Q0E5IvZYMrh6paK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"l7QvImPu0XvB"},"outputs":[],"source":["import sklearn\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.cross_decomposition import PLSRegression\n","from sklearn.discriminant_analysis import (\n","    LinearDiscriminantAnalysis,\n","    QuadraticDiscriminantAnalysis\n",")\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import (\n","    RandomForestClassifier,\n","    GradientBoostingClassifier\n",")\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","import numpy as np\n","\n","from module.common import parameter_grid"]},{"cell_type":"markdown","source":["## Scikit-Learn 클래스\n","\n","### Logistic Regression\n","- **클래스**: `sklearn.linear_model.LogisticRegression`\n","- **설명**: 특성 데이터셋에 효율적인 이진 분류를 위한 로지스틱 회귀를 사용하기 위해 import합니다.\n","\n","### PLS Regression\n","- **클래스**: `sklearn.cross_decomposition.PLSRegression`\n","- **설명**: 고차원 데이터셋에 적합한 독립 변수와 종속 변수 행렬을 예측하는 부분 최소 제곱 회귀를 사용하기 위해 import합니다.\n","\n","### Linear Discriminant Analysis\n","- **클래스**: `sklearn.discriminant_analysis.LinearDiscriminantAnalysis`\n","- **설명**: 다중 클래스 분류와 차원 축소에 사용되는 선형 판별 분석입니다.\n","\n","### Quadratic Discriminant Analysis\n","- **클래스**: `sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis`\n","- **설명**: 클래스 분포가 가우시안 분포일 때 유용한 2차 판별 분석입니다.\n","\n","### Decision Tree Classifier\n","- **클래스**: `sklearn.tree.DecisionTreeClassifier`\n","- **설명**: 비선형 데이터셋에 적합한 결정 트리 분류기입니다.\n","\n","### Random Forest Classifier\n","- **클래스**: `sklearn.ensemble.RandomForestClassifier`\n","- **설명**: 분류 작업에 효과적인 결정 트리 기반의 앙상블 학습 방법을 구현한 랜덤 포레스트 분류기입니다.\n","\n","### Gradient Boosting Classifier\n","- **클래스**: `sklearn.ensemble.GradientBoostingClassifier`\n","- **설명**: 단계적으로 모델을 구축하는 그래디언트 부스팅 분류기입니다.\n","\n","************\n","\n","### XGBoost Classifier\n","- **라이브러리**: `xgboost`\n","- **클래스**: `XGBClassifier`\n","- **설명**: XGBoost는 향상된 그라디언트 부스팅 시스템으로, 큰 규모의 데이터셋에서 뛰어난 속도와 성능을 제공합니다. 병렬 처리, 트리 가지치기, 하드웨어 최적화가 가능합니다.\n","\n","### LightGBM Classifier\n","- **라이브러리**: `lightgbm`\n","- **클래스**: `LGBMClassifier`\n","- **설명**: LightGBM은 메모리 사용량이 적고, 학습에 소요되는 시간이 짧은 그라디언트 부스팅 프레임워크입니다.\n","\n","### MLP Classifier\n","- **클래스**: `sklearn.neural_network.MLPClassifier`\n","- **설명**: 다층 퍼셉트론(신경망)을 구현하는 분류기입니다.\n","\n","## NumPy\n","- **라이브러리**: `numpy`\n","- **설명**: 다차원 배열 및 수치 계산을 위한 핵심 라이브러리입니다.\n","\n","## 사용자 정의 함수\n","- **함수**: `parameter_grid`\n","- **모듈**: `module.common`\n","- **설명**: module.commmon에 정의된 그리드 생성 함수로 param_dict 사전을 입력받아 가능한 모든 매개변수 조합을 생성하는 함수입니다.\n"],"metadata":{"id":"BE-6DcFh3PEy"}},{"cell_type":"code","source":["def load_model(model: str, seed: int, param: dict):\n","    if model == 'logistic':\n","        clf = LogisticRegression(random_state = seed, **param)\n","\n","    elif model == 'dt':\n","        clf = DecisionTreeClassifier(random_state = seed, **param)\n","\n","    elif model == 'rf':\n","        clf = RandomForestClassifier(random_state = seed, **param)\n","\n","    elif model == 'gbt':\n","        clf = GradientBoostingClassifier(random_state = seed, **param)\n","\n","    elif model == 'xgb':\n","        clf = XGBClassifier(random_state = seed, **param)\n","\n","    elif model == 'lgb':\n","        clf = LGBMClassifier(random_state = seed, **param)\n","\n","    elif model == 'lda':\n","        clf = LinearDiscriminantAnalysis(**param)\n","\n","    elif model == 'qda':\n","        clf = QuadraticDiscriminantAnalysis(**param)\n","\n","    elif model == 'plsda':\n","        clf = PLSRegression(**param)\n","\n","    elif model == 'mlp':\n","        clf = MLPClassifier(random_state = seed, **param)\n","\n","    return clf"],"metadata":{"id":"1vubc6UW1n82"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **load_model**\n","`load_model` 함수는 입력받은 머신 러닝 모델 이름에 따라 모델을 초기화하여 반환합니다.\n","\n","- **매개변수**:\n","  - `model`: 문자열 형태로. 초기화하고자 하는 모델의 이름을 입력받습니다.\n","  - `seed`: 모델의 재현 가능성을 위해 사용되는 정수 시드 값을 입력받습니다.\n","  - `param`: 사전 형태로 모델의 하이퍼파라미터를 입력받습니다.\n","\n","- **동작 과정**:\n","  1. 입력된 `model` 문자열에 따라 해당하는 머신 러닝 모델을 선택합니다.\n","  2. `param` 매개변수를 사용하여 모델에 하이퍼파라미터를 전달합니다.\n","  3. `random_state`는 `seed` 값으로 설정합니다.\n","  4. 초기화된 모델 `clf`을 반환합니다.\n","\n","- **사용된 모델 10가지**:\n","  - Logistic Regression (`LogisticRegression`)\n","  - Decision Tree (`DecisionTreeClassifier`)\n","  - Random Forest (`RandomForestClassifier`)\n","  - Gradient Boosting (`GradientBoostingClassifier`)\n","  - XGBoost (`XGBClassifier`)\n","  - LightGBM (`LGBMClassifier`)\n","  - Linear Discriminant Analysis (`LinearDiscriminantAnalysis`)\n","  - Quadratic Discriminant Analysis (`QuadraticDiscriminantAnalysis`)\n","  - PLS Regression (`PLSRegression`)\n","  - MLP Classifier (`MLPClassifier`)\n"],"metadata":{"id":"pLVPzj17LlfN"}},{"cell_type":"code","source":["def load_hyperparameter(model: str):\n","    if model == 'logistic':\n","        params_dict = {\n","            'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n","                  1, 2, 3, 4, 5, 7, 9, 11, 15, 20, 25, 30, 35, 40, 50, 100],\n","            'penalty': ['l1', 'l2'],\n","            'solver': ['liblinear', 'saga']\n","        }\n","\n","    elif model == 'dt':\n","        params_dict = {\n","            'criterion': ['gini', 'entropy'],\n","            'max_depth': [None, 1, 2, 3, 4, 5],\n","            'min_samples_split': [2, 3, 4],\n","            'min_samples_leaf': [1, 2, 3]\n","        }\n","\n","    elif model == 'rf':\n","        params_dict = {\n","            'n_estimators': [3, 5, 10, 15, 20, 30, 50, 90, 95,\n","                            100, 125, 130, 150],\n","            'criterion': ['gini'],\n","            'min_samples_split': [2, 4],\n","            'min_samples_leaf': [1, 3],\n","            'max_features': ['sqrt', 'log2']\n","        }\n","\n","    elif model == 'gbt':\n","        params_dict = {\n","            'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n","            'n_estimators': [5, 10, 50, 100, 130],\n","            'max_depth': [1, 2, 3, 4]\n","        }\n","\n","    elif model == 'xgb':\n","        params_dict = {\n","            'min_child_weight': [1, 2, 3, 5],\n","            'max_depth': [3, 6, 9],\n","            'gamma': np.linspace(0, 3, 10),\n","            # 'objective': ['multi:softmax'],\n","            'booster': ['gbtree']\n","        }\n","\n","    elif model == 'lgb':\n","        params_dict = {\n","            # 'objective': ['multiclass'],\n","            'num_leaves': [15, 21, 27, 31, 33],\n","            'max_depth': [-1, 2],\n","            'n_estimators': [5, 10, 50, 100, 130],\n","            'min_child_samples': [10, 20, 25, 30]\n","        }\n","\n","    elif model == 'lda':\n","        params_dict1 = {\n","            'solver': ['lsqr', 'eigen'],\n","            'shrinkage': np.logspace(-3, 0, 30)\n","        }\n","        params_dict2 = {\n","            'solver': ['svd'],\n","            'tol': np.logspace(-5, -3, 20)\n","        }\n","\n","    elif model == 'qda':\n","        params_dict = {\n","            'reg_param': np.append(np.array([0]), np.logspace(-5, 0, 10)),\n","            'tol': np.logspace(-5, -3, 10)\n","        }\n","\n","    elif model == 'plsda':\n","        params_dict = {\n","            'n_components': [1, 2, 3],\n","            'max_iter': [300, 500, 1000],\n","            'tol': np.logspace(-7, -5, 10)\n","        }\n","\n","    elif model == 'mlp':\n","        params_dict = {\n","            'hidden_layer_sizes': [(50), (100, 50, 10), (100, 70, 50, 30, 10)],\n","            'activation': ['relu', 'tanh'],\n","            'solver': ['adam', 'sgd'],\n","            'alpha': [0.0001, 0.001],\n","            'learning_rate_init': [0.001, 0.01, 0.1],\n","            'max_iter': [50, 100, 200]\n","        }\n","\n","    #\n","    if model == 'lda':\n","        params = parameter_grid(params_dict1)\n","        params.extend(parameter_grid(params_dict2))\n","    else:\n","        params = parameter_grid(params_dict)\n","\n","    return params"],"metadata":{"id":"sMIpld2Y1spn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **load_hyperparameter**\n","\n","`load_hyperparameter` 함수는 입은 받은 머신 러닝 모델에 대한 하이퍼파라미터 그리드를 생성하여 반환하는 함수입니다.\n","\n","- **매개변수**:\n","  - `model`: 하이퍼파라미터를 생성할 모델의 이름을 문자열로 입력받습니다.\n","\n","- **동작 과정**:\n","  1. 모델 이름에 따라 해당 모델의 하이퍼파라미터 설정을 담고 있는 `params_dict` dictionary를 생성합니다.\n","  2. 각 모델에 대한 하이퍼파라미터 값의 범위를 지정합니다.\n","  3. `parameter_grid` 함수를 사용하여 가능한 모든 하이퍼파라미터 조합을 생성합니다.\n","  4. 생성된 하이퍼파라미터 조합을 리스트 형태로 반환합니다.\n","\n","- **모델 및 하이퍼파라미터**:\n","  - Logistic Regression: `C`, `penalty`, `solver`\n","  - Decision Tree: `criterion`, `max_depth`, `min_samples_split`\n","  - Random Forest: `n_estimators`, `criterion`, `min_samples_split`\n","  - Gradient Boosting: `learning_rate`, `n_estimators`, `max_depth`\n","  - XGBoost: `min_child_weight`, `max_depth`, `gamma`\n","  - LightGBM: `num_leaves`, `max_depth`, `n_estimators`\n","  - Linear Discriminant Analysis: `solver`, `shrinkage`, `tol`\n","  - Quadratic Discriminant Analysis: `reg_param`, `tol`\n","  - PLS Regression: `n_components`, `max_iter`, `tol`\n","  - MLP Classifier: `hidden_layer_sizes`, `activation`, `solver`\n"],"metadata":{"id":"djCnuOUaQ4qf"}}]}